{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f26fa959-7a2c-4012-babc-13416d05c8bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "###REQUIRED LIBRARIES\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "import string\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fe0fc533-a951-4bec-9d3f-c35a77200d90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Consumer complaint narrative</th>\n",
       "      <th>Product</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>My sister initiated an internal transfer of {$...</td>\n",
       "      <td>Money transfer, virtual currency, or money ser...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I received a title loan on a a temporary card....</td>\n",
       "      <td>Prepaid card</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I've complained about procollect and this fals...</td>\n",
       "      <td>Debt collection</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>This is for a card with Sheels/FNBO XXXX XXXXX...</td>\n",
       "      <td>Credit card</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>XXXX XXXX XXXX XXXX XXXX XXXX XXXX XXXX XXXX, ...</td>\n",
       "      <td>Credit reporting or other personal consumer re...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Consumer complaint narrative  \\\n",
       "0  My sister initiated an internal transfer of {$...   \n",
       "1  I received a title loan on a a temporary card....   \n",
       "2  I've complained about procollect and this fals...   \n",
       "3  This is for a card with Sheels/FNBO XXXX XXXXX...   \n",
       "4  XXXX XXXX XXXX XXXX XXXX XXXX XXXX XXXX XXXX, ...   \n",
       "\n",
       "                                             Product  \n",
       "0  Money transfer, virtual currency, or money ser...  \n",
       "1                                       Prepaid card  \n",
       "2                                    Debt collection  \n",
       "3                                        Credit card  \n",
       "4  Credit reporting or other personal consumer re...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### LOAD AND EXPLORE DATASET\n",
    "\n",
    "df = pd.read_csv(\"complaints.csv\")\n",
    "df = df[['Consumer complaint narrative', 'Product']]\n",
    "df = df.dropna()\n",
    "df = df[df['Consumer complaint narrative'].notnull()]\n",
    "df = df.reset_index(drop=True)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b9ffa5ed-ef10-49e2-991a-f556f10dc3d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "### ENCODE TARGET LABELS\n",
    "\n",
    "\n",
    "target_map = {\n",
    "    'Credit reporting, credit repair services, or other personal consumer reports': 0,\n",
    "    'Debt collection': 1,\n",
    "    'Consumer Loan': 2,\n",
    "    'Mortgage': 3\n",
    "}\n",
    "\n",
    "df = df[df['Product'].isin(target_map.keys())]\n",
    "df['Category'] = df['Product'].map(target_map)\n",
    "df = df[['Consumer complaint narrative', 'Category']]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "71adc991-b0d3-43c8-b17d-1ce0ac73af6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "### TEXT PREPROCESSING\n",
    "\n",
    "nltk.download('stopwords', quiet=True)\n",
    "nltk.download('wordnet', quiet=True)\n",
    "\n",
    "\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def preprocess(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'\\d+', '', text)  # Remove numbers\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))  # Remove punctuation\n",
    "    tokens = text.split()\n",
    "    tokens = [lemmatizer.lemmatize(word) for word in tokens if word not in stop_words]\n",
    "    return \" \".join(tokens)\n",
    "\n",
    "df['CleanText'] = df['Consumer complaint narrative'].apply(preprocess)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a6819d4b-ec7c-4178-a944-356c1ead0ce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "### VECTORIZATION\n",
    "\n",
    "tfidf = TfidfVectorizer(max_features=5000)\n",
    "X = tfidf.fit_transform(df['CleanText'])\n",
    "y = df['Category']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d99995b0-1bf7-4f6e-bdcb-c70ea2b4a8db",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### TRAIN-TEST SPLIT\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "83a3c331-9050-46a4-ad40-ffbf5e8f12dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "###TRAIN MODELS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6a1c80bf-c939-404c-a0b2-6f16018d5d3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "### NAIVE BAYES\n",
    "\n",
    "nb = MultinomialNB()\n",
    "nb.fit(X_train, y_train)\n",
    "y_pred_nb = nb.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d08847dd-c7cd-4ccb-a954-d9034eda6ff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "### LOGISTIC REGRESSION\n",
    "\n",
    "lr = LogisticRegression(max_iter=200)\n",
    "lr.fit(X_train, y_train)\n",
    "y_pred_lr = lr.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4dbbe786-34c6-4bbc-9e5c-1e2d436b7163",
   "metadata": {},
   "outputs": [],
   "source": [
    "### SUPPORT  VECTOR CLASSIFIER\n",
    "\n",
    "svc = LinearSVC()\n",
    "svc.fit(X_train, y_train)\n",
    "y_pred_svc = svc.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8fb03db2-388f-4fe3-a7f7-5b8523cc9134",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Naive Bayes ---\n",
      "Accuracy: 0.8731653270797527\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.92      0.91    161272\n",
      "           1       0.83      0.74      0.78     66293\n",
      "           2       0.46      0.27      0.34      1882\n",
      "           3       0.82      0.94      0.88     25980\n",
      "\n",
      "    accuracy                           0.87    255427\n",
      "   macro avg       0.75      0.72      0.73    255427\n",
      "weighted avg       0.87      0.87      0.87    255427\n",
      "\n",
      "Confusion Matrix:\n",
      " [[148853   8845    423   3151]\n",
      " [ 15227  49125    165   1776]\n",
      " [   366    488    505    523]\n",
      " [   855    576      2  24547]]\n",
      "\n",
      "\n",
      "--- Logistic Regression ---\n",
      "Accuracy: 0.9057656394977821\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.95      0.93    161272\n",
      "           1       0.86      0.82      0.84     66293\n",
      "           2       0.69      0.39      0.50      1882\n",
      "           3       0.92      0.93      0.92     25980\n",
      "\n",
      "    accuracy                           0.91    255427\n",
      "   macro avg       0.85      0.77      0.80    255427\n",
      "weighted avg       0.90      0.91      0.90    255427\n",
      "\n",
      "Confusion Matrix:\n",
      " [[152543   7464    153   1112]\n",
      " [ 11312  54043    149    789]\n",
      " [   534    445    730    173]\n",
      " [  1338    580     21  24041]]\n",
      "\n",
      "\n",
      "--- SVC ---\n",
      "Accuracy: 0.9061767158522788\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.95      0.93    161272\n",
      "           1       0.87      0.81      0.84     66293\n",
      "           2       0.77      0.31      0.44      1882\n",
      "           3       0.92      0.93      0.92     25980\n",
      "\n",
      "    accuracy                           0.91    255427\n",
      "   macro avg       0.87      0.75      0.78    255427\n",
      "weighted avg       0.90      0.91      0.90    255427\n",
      "\n",
      "Confusion Matrix:\n",
      " [[152802   7178     75   1217]\n",
      " [ 11451  53950     84    808]\n",
      " [   602    509    577    194]\n",
      " [  1239    592     16  24133]]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### EVALUATION\n",
    "\n",
    "def evaluate_model(name, y_true, y_pred):\n",
    "    print(f\"--- {name} ---\")\n",
    "    print(\"Accuracy:\", accuracy_score(y_true, y_pred))\n",
    "    print(\"Classification Report:\\n\", classification_report(y_true, y_pred))\n",
    "    print(\"Confusion Matrix:\\n\", confusion_matrix(y_true, y_pred))\n",
    "    print(\"\\n\")\n",
    "\n",
    "evaluate_model(\"Naive Bayes\", y_test, y_pred_nb)\n",
    "evaluate_model(\"Logistic Regression\", y_test, y_pred_lr)\n",
    "evaluate_model(\"SVC\", y_test, y_pred_svc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8a136795-5643-4620-96f9-bef48166cd3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Category: 1\n"
     ]
    }
   ],
   "source": [
    "### MAKE A PREDICTION\n",
    "\n",
    "sample = [\"I am unable to get any resolution from my debt collector\"]\n",
    "sample_cleaned = preprocess(sample[0])\n",
    "sample_vec = tfidf.transform([sample_cleaned])\n",
    "print(\"Predicted Category:\", nb.predict(sample_vec)[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5d46fba-16c2-47ed-bdff-26d11c200eb5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
